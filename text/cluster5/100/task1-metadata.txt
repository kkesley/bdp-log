Name	Value
mapreduce.jobtracker.address	local
dfs.namenode.resource.check.interval	5000
hadoop.security.group.mapping.ldap.posix.attr.uid.name	uidNumber
mapreduce.jobhistory.client.thread-count	10
yarn.application.classpath	$HADOOP_CONF_DIR, $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*, $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*, $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*, $HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*, /usr/lib/hadoop-lzo/lib/*, /usr/share/aws/emr/emrfs/conf, /usr/share/aws/emr/emrfs/lib/*, /usr/share/aws/emr/emrfs/auxlib/*, /usr/share/aws/emr/lib/*, /usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar, /usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar, /usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar, /usr/lib/spark/yarn/lib/datanucleus-api-jdo.jar, /usr/lib/spark/yarn/lib/datanucleus-core.jar, /usr/lib/spark/yarn/lib/datanucleus-rdbms.jar, /usr/share/aws/emr/cloudwatch-sink/lib/*, /usr/share/aws/aws-java-sdk/*
yarn.admin.acl	*
hadoop.proxyuser.presto.hosts	*
yarn.app.mapreduce.am.job.committer.cancel-timeout	60000
mapreduce.job.emit-timeline-data	false
dfs.journalnode.rpc-address	0.0.0.0:8485
yarn.resourcemanager.leveldb-state-store.path	${hadoop.tmp.dir}/yarn/system/rmstore
mapred.mapper.new-api	false
ipc.client.connection.maxidletime	10000
yarn.nodemanager.process-kill-wait.ms	2000
yarn.minicluster.use-rpc	false
io.map.index.interval	128
dfs.namenode.https-address	ip-192-168-27-182.ec2.internal:50470
dfs.mover.max-no-move-interval	60000
mapreduce.task.profile.reduces	0-2
fs.s3n.multipart.uploads.enabled	true
hadoop.util.hash.type	murmur
dfs.namenode.replication.min	1
yarn.app.mapreduce.am.jhs.backup-dir	file:///var/log/hadoop-mapreduce/history
fs.s3a.path.style.access	false
dfs.namenode.fs-limits.min-block-size	1048576
fs.AbstractFileSystem.file.impl	org.apache.hadoop.fs.local.LocalFs
net.topology.script.number.args	100
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs	86400
mapreduce.map.output.compress.codec	org.apache.hadoop.io.compress.SnappyCodec
yarn.nodemanager.windows-container.memory-limit.enabled	false
mapreduce.input.fileinputformat.split.minsize	0
hadoop.security.group.mapping	org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
mapreduce.jobtracker.system.dir	${hadoop.tmp.dir}/mapred/system
mapreduce.job.end-notification.max.attempts	5
mapreduce.reduce.speculative	true
yarn.nodemanager.localizer.cache.cleanup.interval-ms	600000
yarn.nodemanager.node-labels.resync-interval-ms	120000
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size	10000
dfs.namenode.replication.interval	3
yarn.resourcemanager.admin.address	${yarn.resourcemanager.hostname}:8033
mapreduce.job.maps	10
mapreduce.job.ubertask.enable	false
yarn.timeline-service.entity-group-fs-store.retain-seconds	604800
dfs.client.use.datanode.hostname	false
mapreduce.am.max-attempts	2
yarn.nodemanager.amrmproxy.enable	false
yarn.resourcemanager.zk-num-retries	1000
s3.blocksize	67108864
dfs.datanode.data.dir	/mnt/hdfs
mapreduce.reduce.shuffle.parallelcopies	20
adl.feature.ownerandgroup.enableupn	false
fs.s3.buffer.dir	/mnt/s3
mapreduce.job.finish-when-all-reducers-done	false
hadoop.registry.zk.retry.ceiling.ms	60000
dfs.datanode.data.dir.perm	700
yarn.nodemanager.env-whitelist	JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME
dfs.namenode.xattrs.enabled	true
dfs.datanode.transfer.socket.send.buffer.size	0
dfs.datanode.bp-ready.timeout	20
yarn.app.mapreduce.client.job.max-retries	0
yarn.nodemanager.linux-container-executor.cgroups.hierarchy	/hadoop-yarn
yarn.resourcemanager.recovery.enabled	false
yarn.app.mapreduce.am.container.log.backups	0
yarn.nodemanager.disk-health-checker.interval-ms	120000
tmparchives	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/domainrank_ccmr.tar.gz#domainrank_ccmr.tar.gz
dfs.namenode.list.cache.directives.num.responses	100
yarn.nodemanager.node-labels.provider.fetch-interval-ms	600000
fs.s3a.max.total.tasks	5
mapreduce.reduce.maxattempts	4
mapreduce.shuffle.port	13562
yarn.resourcemanager.resource-tracker.client.thread-count	64
dfs.namenode.replication.considerLoad	true
yarn.resourcemanager.webapp.cross-origin.enabled	false
yarn.nodemanager.delete.thread-count	4
yarn.nodemanager.admin-env	MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
yarn.resourcemanager.proxy-user-privileges.enabled	false
mapreduce.job.speculative.speculative-cap-total-tasks	0.01
mapreduce.job.speculative.slowtaskthreshold	1.0
ftp.replication	3
yarn.sharedcache.cleaner.initial-delay-mins	10
s3native.client-write-packet-size	65536
file.bytes-per-checksum	512
dfs.datanode.slow.io.warning.threshold.ms	300
rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB	org.apache.hadoop.ipc.ProtobufRpcEngine
mapreduce.task.skip.start.attempts	2
hadoop.security.dns.log-slow-lookups.threshold.ms	1000
dfs.namenode.reject-unresolved-dn-topology-mapping	false
yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size	10485760
yarn.sharedcache.admin.address	0.0.0.0:8047
mapreduce.job.jvm.numtasks	20
dfs.namenode.top.num.users	10
yarn.nodemanager.linux-container-executor.cgroups.mount	false
yarn.sharedcache.checksum.algo.impl	org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
mapreduce.job.classloader	false
yarn.log-aggregation-enable	true
mapreduce.reduce.shuffle.fetch.retry.interval-ms	1000
yarn.resourcemanager.nodemanager.minimum.version	NONE
hadoop.proxyuser.hue.groups	*
hadoop.security.kms.client.encrypted.key.cache.size	500
mapreduce.output.fileoutputformat.compress.type	BLOCK
hadoop.hdfs.configuration.version	1
yarn.nodemanager.log.retain-seconds	10800
yarn.timeline-service.entity-group-fs-store.done-dir	/tmp/entity-file-history/done/
yarn.nodemanager.local-cache.max-files-per-directory	8192
mapreduce.job.end-notification.retry.interval	1000
ha.failover-controller.new-active.rpc-timeout.ms	60000
hadoop.ssl.hostname.verifier	DEFAULT
dfs.client.read.shortcircuit	false
s3native.blocksize	67108864
dfs.client.failover.sleep.base.millis	500
dfs.permissions.superusergroup	hadoop
hadoop.registry.zk.retry.times	5
dfs.client.socket.send.buffer.size	0
dfs.blockreport.initialDelay	0
yarn.scheduler.maximum-allocation-mb	2048
mapreduce.task.io.sort.factor	48
dfs.client.failover.sleep.max.millis	15000
fs.s3.sleepTimeSeconds	10
yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs	86400
yarn.nodemanager.log.deletion-threads-count	4
ha.health-monitor.rpc-timeout.ms	45000
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users	true
fs.AbstractFileSystem.viewfs.impl	org.apache.hadoop.fs.viewfs.ViewFs
fs.ftp.host	0.0.0.0
fs.adl.oauth2.access.token.provider.type	ClientCredential
yarn.web-proxy.address	ip-192-168-27-182.ec2.internal:20888
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user	nobody
yarn.timeline-service.entity-group-fs-store.active-dir	/tmp/entity-file-history/active
fs.s3a.impl	org.apache.hadoop.fs.s3a.S3AFileSystem
dfs.namenode.fs-limits.max-blocks-per-file	1048576
mapreduce.tasktracker.http.threads	60
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs	86400
yarn.resourcemanager.delegation.key.update-interval	86400000
yarn.nodemanager.webapp.https.address	0.0.0.0:8044
dfs.namenode.hosts.provider.classname	org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager
dfs.balancer.keytab.enabled	false
dfs.namenode.lifeline.handler.ratio	0.10
io.compression.codec.bzip2.library	system-native
mapreduce.map.skip.maxrecords	0
ipc.ping.interval	60000
mapreduce.jobhistory.loadedjobs.cache.size	5
dfs.storage.policy.enabled	true
mapreduce.client.output.filter	FAILED
yarn.nodemanager.resource.count-logical-processors-as-cores	false
yarn.nodemanager.resource.system-reserved-memory-mb	-1
yarn.timeline-service.client.best-effort	false
dfs.datanode.block-pinning.enabled	false
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled	true
mapreduce.job.speculative.retry-after-no-speculate	1000
s3native.stream-buffer-size	4096
io.seqfile.local.dir	${hadoop.tmp.dir}/io/local
dfs.encrypt.data.transfer.cipher.key.bitlength	128
dfs.datanode.sync.behind.writes	false
yarn.app.mapreduce.am.log.level	INFO
mapreduce.job.application.attempt.id	1
dfs.namenode.stale.datanode.interval	30000
mapreduce.task.io.sort.mb	200
yarn.resourcemanager.zk-state-store.parent-path	/rmstore
fs.client.resolve.remote.symlinks	true
hadoop.ssl.enabled.protocols	TLSv1
mapreduce.reduce.cpu.vcores	1
yarn.client.failover-retries	0
mapreduce.jobhistory.address	ip-192-168-27-182.ec2.internal:10020
hadoop.ssl.enabled	false
dfs.namenode.name.dir	/mnt/namenode
mapreduce.task.local-fs.write-limit.bytes	-1
yarn.resourcemanager.configuration.file-system-based-store	/yarn/conf
dfs.block.access.token.enable	false
dfs.webhdfs.rest-csrf.methods-to-ignore	GET,OPTIONS,HEAD,TRACE
mapreduce.job.speculative.retry-after-speculate	15000
dfs.datanode.address	0.0.0.0:50010
yarn.nodemanager.log-aggregation.policy.class	org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy
ipc.client.connect.max.retries	10
hadoop.proxyuser.presto.groups	*
hadoop.security.kms.client.timeout	60
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms	60000
yarn.resourcemanager.reservation-system.planfollower.time-step	1000
dfs.webhdfs.rest-csrf.custom-header	X-XSRF-HEADER
dfs.datanode.handler.count	10
yarn.resourcemanager.ha.automatic-failover.embedded	true
hadoop.proxyuser.oozie.groups	*
yarn.nodemanager.log-container-debug-info.enabled	false
mapreduce.task.profile.map.params	${mapreduce.task.profile.params}
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms	1000
dfs.namenode.block-placement-policy.default.prefer-local-node	true
dfs.namenode.resource.checked.volumes.minimum	1
dfs.http.client.retry.max.attempts	10
yarn.resourcemanager.keytab	/etc/krb5.keytab
hadoop.security.key.provider.path	kms://http@ip-192-168-27-182.ec2.internal:9700/kms
yarn.cluster.max-application-priority	0
yarn.log-aggregation-status.time-out.ms	600000
yarn.client.max-cached-nodemanagers-proxies	0
fs.trash.checkpoint.interval	0
yarn.sharedcache.app-checker.class	org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
dfs.journalnode.http-address	0.0.0.0:8480
yarn.app.mapreduce.am.staging-dir	/tmp/hadoop-yarn/staging
yarn.nm.liveness-monitor.expiry-interval-ms	600000
mapreduce.reduce.shuffle.merge.percent	0.66
dfs.namenode.retrycache.heap.percent	0.03f
ipc.client.connect.timeout	20000
dfs.image.transfer-bootstrap-standby.bandwidthPerSec	0
yarn.nodemanager.local-dirs	/mnt/yarn
dfs.balancer.block-move.timeout	0
yarn.nodemanager.recovery.enabled	false
yarn.resourcemanager.am.max-attempts	2
s3.replication	3
yarn.timeline-service.client.internal-timers-ttl-secs	420
yarn.nodemanager.resource.pcores-vcores-multiplier	1.0
hadoop.kerberos.min.seconds.before.relogin	60
dfs.image.compress	false
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction	1.0
dfs.namenode.edit.log.autoroll.multiplier.threshold	2.0
hadoop.security.group.mapping.ldap.ssl	false
dfs.namenode.checkpoint.check.period	60
fs.defaultFS	hdfs://ip-192-168-27-182.ec2.internal:8020
hadoop.security.group.mapping.ldap.search.attr.group.name	cn
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage	90.0
dfs.namenode.service.handler.count	10
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled	false
mapreduce.map.sort.spill.percent	0.80
hadoop.security.crypto.codec.classes.aes.ctr.nopadding	org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec
dfs.namenode.http-address	ip-192-168-27-182.ec2.internal:50070
hadoop.security.groups.negative-cache.secs	30
hadoop.ssl.server.conf	ssl-server.xml
yarn.client.nodemanager-client-async.thread-pool-max-size	500
mapreduce.jobtracker.staging.root.dir	${hadoop.tmp.dir}/mapred/staging
yarn.minicluster.yarn.nodemanager.resource.memory-mb	4096
mapreduce.jobhistory.admin.address	0.0.0.0:10033
dfs.namenode.startup.delay.block.deletion.sec	0
yarn.nodemanager.health-checker.interval-ms	600000
dfs.namenode.checkpoint.max-retries	3
ftp.client-write-packet-size	65536
yarn.timeline-service.keytab	/etc/krb5.keytab
mapreduce.reduce.shuffle.fetch.retry.enabled	${yarn.nodemanager.recovery.enabled}
hadoop.job.history.user.location	none
yarn.app.mapreduce.task.container.log.backups	0
dfs.heartbeat.interval	3
ha.zookeeper.session-timeout.ms	5000
hadoop.security.key.default.bitlength	256
hadoop.http.authentication.signature.secret.file	${user.home}/hadoop-http-auth-signature-secret
yarn.nodemanager.log-aggregation.compression-type	none
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms	10000
yarn.nodemanager.log-dirs	/var/log/hadoop-yarn/containers
mapreduce.job.speculative.minimum-allowed-tasks	10
dfs.datanode.cache.revocation.timeout.ms	900000
mapreduce.jobhistory.recovery.store.class	org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
mapreduce.task.combine.progress.records	10000
yarn.nodemanager.recovery.supervised	false
yarn.nodemanager.amrmproxy.interceptor-class.pipeline	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor
ipc.client.low-latency	false
yarn.nodemanager.address	${yarn.nodemanager.hostname}:8041
mapreduce.job.reduces	1
yarn.timeline-service.address	${yarn.timeline-service.hostname}:10200
yarn.resourcemanager.configuration.provider-class	org.apache.hadoop.yarn.LocalConfigurationProvider
hadoop.security.kms.client.encrypted.key.cache.expiry	43200000
yarn.sharedcache.enabled	false
tfile.io.chunk.size	1048576
hadoop.registry.zk.session.timeout.ms	60000
ha.health-monitor.sleep-after-disconnect.ms	1000
yarn.timeline-service.http-cross-origin.enabled	true
mapreduce.tasktracker.reduce.tasks.maximum	1
mapred.input.format.class	org.apache.hadoop.mapred.TextInputFormat
dfs.datanode.directoryscan.threads	1
yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs	20
dfs.datanode.directoryscan.interval	21600
mapreduce.job.cache.files.timestamps	1537435509756,1537435524091,1537435516480
hadoop.http.authentication.token.validity	36000
ha.failover-controller.graceful-fence.rpc-timeout.ms	5000
mapreduce.jobhistory.cleaner.interval-ms	86400000
dfs.namenode.datanode.registration.ip-hostname-check	true
dfs.namenode.backup.http-address	0.0.0.0:50105
stream.map.streamprocessor	%2Fbin%2Fbash+-x+setup-wrapper.sh+python+domainrank.py+--step-num%3D2+--mapper+--iterations+1+--sortrank+1
yarn.resourcemanager.reservation-system.enable	false
mapreduce.reduce.shuffle.read.timeout	180000
hadoop.security.crypto.buffer.size	8192
mapreduce.ifile.readahead.bytes	4194304
hadoop.registry.secure	false
dfs.namenode.safemode.min.datanodes	0
yarn.timeline-service.http-authentication.type	simple
dfs.webhdfs.enabled	true
dfs.webhdfs.socket.read-timeout	60s
yarn.dispatcher.drain-events.timeout	300000
dfs.namenode.avoid.write.stale.datanode	false
yarn.log-aggregation.retain-seconds	172800
mapreduce.job.complete.cancel.delegation.tokens	true
fs.s3a.multiobjectdelete.enable	true
yarn.resourcemanager.fail-fast	${yarn.fail-fast}
mapreduce.shuffle.connection-keep-alive.timeout	5
yarn.scheduler.minimum-allocation-vcores	1
yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed	false
yarn.timeline-service.client.retry-interval-ms	1000
yarn.timeline-service.client.max-retries	30
mapreduce.shuffle.max.threads	0
nfs.exports.allowed.hosts	* rw
dfs.client.mmap.cache.size	256
io.file.buffer.size	65536
dfs.ha.zkfc.nn.http.timeout.ms	20000
yarn.nodemanager.container-metrics.unregister-delay-ms	10000
rpc.engine.org.apache.hadoop.ipc.ProtocolMetaInfoPB	org.apache.hadoop.ipc.ProtobufRpcEngine
dfs.namenode.checkpoint.txns	1000000
ipc.client.connect.retry.interval	1000
yarn.nodemanager.container-metrics.period-ms	-1
mapreduce.reduce.shuffle.connect.timeout	180000
yarn.resourcemanager.fs.state-store.uri	${hadoop.tmp.dir}/yarn/system/rmstore
hadoop.registry.zk.connection.timeout.ms	15000
fs.AbstractFileSystem.adl.impl	org.apache.hadoop.fs.adl.Adl
dfs.namenode.list.openfiles.num.responses	1000
mapred.queue.default.acl-administer-jobs	*
mapreduce.job.submithostaddress	192.168.27.182
dfs.cachereport.intervalMsec	10000
yarn.timeline-service.client.fd-flush-interval-secs	10
yarn.app.mapreduce.am.container.log.limit.kb	0
yarn.nodemanager.resourcemanager.minimum.version	NONE
fs.s3bfs.impl	org.apache.hadoop.fs.s3.S3FileSystem
yarn.resourcemanager.address	ip-192-168-27-182.ec2.internal:8032
file.stream-buffer-size	4096
mapreduce.job.ubertask.maxreduces	1
yarn.resourcemanager.nodemanager-connect-retries	10
dfs.http.client.retry.policy.enabled	false
ipc.client.idlethreshold	4000
mapred.mapper.class	org.apache.hadoop.streaming.PipeMapper
ftp.stream-buffer-size	4096
yarn.sharedcache.client-server.address	0.0.0.0:8045
dfs.client.failover.connection.retries.on.timeouts	0
dfs.namenode.replication.work.multiplier.per.iteration	2
hadoop.http.authentication.simple.anonymous.allowed	true
yarn.client.nodemanager-connect.retry-interval-ms	10000
yarn.nodemanager.linux-container-executor.resources-handler.class	org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
yarn.timeline-service.leveldb-timeline-store.read-cache-size	104857600
hadoop.security.authentication	simple
dfs.image.compression.codec	org.apache.hadoop.io.compress.DefaultCodec
mapreduce.task.files.preserve.failedtasks	false
dfs.client.read.shortcircuit.streams.cache.size	256
mapreduce.reduce.skip.proc-count.auto-incr	true
file.replication	1
yarn.nodemanager.amrmproxy.client.thread-count	25
mapreduce.jobhistory.joblist.cache.size	20000
yarn.resourcemanager.work-preserving-recovery.enabled	true
dfs.namenode.fs-limits.max-xattrs-per-inode	32
dfs.image.transfer.timeout	60000
yarn.log-aggregation.enable-local-cleanup	false
mapred.output.format.class	org.apache.hadoop.mapred.TextOutputFormat
io.compression.codecs	org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec
nfs.wtmax	1048576
fs.s3a.multipart.purge	false
yarn.resourcemanager.webapp.ui-actions.enabled	true
dfs.secondary.namenode.kerberos.internal.spnego.principal	${dfs.web.authentication.kerberos.principal}
fs.s3a.connection.establish.timeout	5000
dfs.stream-buffer-size	4096
dfs.namenode.invalidate.work.pct.per.iteration	0.32f
fs.s3a.multipart.purge.age	86400
yarn.resourcemanager.scheduler.client.thread-count	64
ipc.maximum.data.length	67108864
tfile.fs.input.buffer.size	262144
hadoop.http.authentication.type	simple
dfs.namenode.list.encryption.zones.num.responses	100
mapreduce.map.cpu.vcores	1
dfs.namenode.decommission.interval	30
fs.AbstractFileSystem.webhdfs.impl	org.apache.hadoop.fs.WebHdfs
ftp.bytes-per-checksum	512
hadoop.workaround.non.threadsafe.getpwuid	true
dfs.user.home.dir.prefix	/user
yarn.nodemanager.pmem-check-enabled	true
dfs.namenode.inotify.max.events.per.rpc	1000
mapreduce.task.profile.maps	0-2
mapreduce.shuffle.ssl.file.buffer.size	65536
stream.reduce.input.writer.class	org.apache.hadoop.streaming.io.TextInputWriter
dfs.datanode.transfer.socket.recv.buffer.size	0
yarn.timeline-service.webapp.https.address	${yarn.timeline-service.hostname}:8190
yarn.label.enabled	true
yarn.app.mapreduce.am.command-opts	-Xmx1024m
yarn.resourcemanager.amlauncher.thread-count	50
dfs.http.client.failover.sleep.max.millis	15000
yarn.sharedcache.nm.uploader.replication.factor	10
dfs.lock.suppress.warning.interval	10s
hadoop.registry.zk.root	/registry
yarn.client.failover-proxy-provider	org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
yarn.timeline-service.client.fd-retain-secs	300
hadoop.caller.context.max.size	128
hadoop.http.cross-origin.max-age	1800
yarn.nodemanager.remote-app-log-dir-suffix	logs
mapreduce.jobhistory.principal	jhs/_HOST@REALM.TLD
nfs.mountd.port	4242
mapreduce.reduce.merge.inmem.threshold	1000
mapreduce.job.output.key.class	org.apache.hadoop.io.Text
dfs.namenode.num.checkpoints.retained	2
mapreduce.job.queuename	default
mapreduce.jobhistory.max-age-ms	604800000
yarn.nodemanager.aux-services.spark_shuffle.class	org.apache.spark.network.yarn.YarnShuffleService
yarn.nodemanager.localizer.client.thread-count	20
yarn.sharedcache.uploader.server.thread-count	50
dfs.namenode.fslock.fair	true
dfs.blockreport.split.threshold	1000000
dfs.datanode.balance.bandwidthPerSec	10m
dfs.block.scanner.volume.bytes.per.second	1048576
tmpfiles	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/domainrank.py#domainrank.py,hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/mrjob.zip#mrjob.zip,hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/setup-wrapper.sh#setup-wrapper.sh
ipc.client.rpc-timeout.ms	0
dfs.default.chunk.view.size	32768
mapreduce.jobhistory.datestring.cache.size	200000
mapreduce.task.profile.params	-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
dfs.namenode.handler.count	64
dfs.image.transfer.bandwidthPerSec	0
yarn.acl.reservation-enable	false
yarn.app.mapreduce.client.max-retries	3
yarn.node-labels.enabled	false
yarn.timeline-service.handler-thread-count	10
ipc.server.listen.queue.size	128
fs.s3a.threads.max	10
yarn.nodemanager.resource.detect-hardware-capabilities	false
yarn.resourcemanager.connect.max-wait.ms	900000
dfs.client.block.write.replace-datanode-on-failure.min-replication	0
yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size	10
mapreduce.job.max.split.locations	10
yarn.resourcemanager.scheduler.class	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.is.minicluster	false
dfs.blocksize	134217728
mapreduce.shuffle.connection-keep-alive.enable	false
fs.s3a.threads.keepalivetime	60
ha.failover-controller.cli-check.rpc-timeout.ms	20000
ha.zookeeper.acl	world:anyone:rwcda
dfs.namenode.write.stale.datanode.ratio	0.5f
dfs.encrypt.data.transfer	false
dfs.datanode.shared.file.descriptor.paths	/dev/shm,/tmp
mapreduce.input.lineinputformat.linespermap	1
yarn.nodemanager.localizer.fetch.thread-count	20
yarn.resourcemanager.scheduler.address	ip-192-168-27-182.ec2.internal:8030
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size	10000
dfs.client.read.shortcircuit.skip.checksum	false
stream.map.output.reader.class	org.apache.hadoop.streaming.io.TextOutputReader
mapreduce.shuffle.ssl.enabled	false
mapreduce.reduce.log.level	INFO
hadoop.registry.rm.enabled	false
dfs.namenode.quota.init-threads	4
dfs.datanode.metrics.logger.period.seconds	600
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size	10
dfs.datanode.use.datanode.hostname	false
yarn.resourcemanager.ha.enabled	false
mapred.reducer.new-api	false
dfs.balancer.address	0.0.0.0:0
yarn.nodemanager.labels	MASTER
dfs.namenode.lock.detailed-metrics.enabled	false
dfs.namenode.rpc-address	ip-192-168-27-182.ec2.internal:8020
dfs.reformat.disabled	false
fs.s3a.multipart.threshold	2147483647
hadoop.http.cross-origin.enabled	false
mapreduce.reduce.shuffle.memory.limit.percent	0.25
dfs.https.server.keystore.resource	ssl-server.xml
yarn.scheduler.include-port-in-node-name	false
dfs.namenode.kerberos.internal.spnego.principal	${dfs.web.authentication.kerberos.principal}
yarn.resourcemanager.state-store.max-completed-applications	${yarn.resourcemanager.max-completed-applications}
stream.reduce.output.reader.class	org.apache.hadoop.streaming.io.TextOutputReader
dfs.datanode.dns.interface	default
map.sort.class	org.apache.hadoop.util.QuickSort
fs.s3a.buffer.dir	${hadoop.tmp.dir}/s3a
mapreduce.reduce.shuffle.retry-delay.max.ms	60000
mapreduce.client.progressmonitor.pollinterval	1000
yarn.app.mapreduce.shuffle.log.limit.kb	0
dfs.datanode.max.locked.memory	0
dfs.namenode.retrycache.expirytime.millis	600000
dfs.datanode.scan.period.hours	504
dfs.client.block.write.replace-datanode-on-failure.best-effort	false
mapreduce.jobhistory.move.interval-ms	180000
dfs.ha.fencing.ssh.connect-timeout	30000
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds	-1
dfs.namenode.fs-limits.max-component-length	255
dfs.webhdfs.rest-csrf.enabled	false
yarn.timeline-service.state-store-class	org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
dfs.datanode.ipc.address	0.0.0.0:50020
dfs.client.block.write.replace-datanode-on-failure.policy	DEFAULT
dfs.namenode.path.based.cache.retry.interval.ms	30000
hadoop.security.crypto.cipher.suite	AES/CTR/NoPadding
fs.s3a.fast.upload.active.blocks	4
dfs.ha.tail-edits.period	60
yarn.timeline-service.generic-application-history.max-applications	10000
hadoop.registry.jaas.context	Client
yarn.resourcemanager.hostname	192.168.27.182
hadoop.security.group.mapping.ldap.search.filter.group	(objectClass=group)
hadoop.shell.safely.delete.limit.num.files	100
hadoop.security.group.mapping.ldap.search.filter.user	(&(objectClass=user)(sAMAccountName={0}))
dfs.namenode.edits.dir	${dfs.namenode.name.dir}
yarn.client.failover-retries-on-socket-timeouts	0
dfs.namenode.decommission.max.concurrent.tracked.nodes	100
ipc.server.log.slow.rpc	false
mapreduce.jobhistory.recovery.store.leveldb.path	${hadoop.tmp.dir}/mapred/history/recoverystore
yarn.sharedcache.store.class	org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
yarn.nodemanager.windows-container.cpu-limit.enabled	false
yarn.nodemanager.vmem-pmem-ratio	5
dfs.namenode.checkpoint.period	3600
yarn.nodemanager.node-labels.provider.fetch-timeout-ms	1200000
mapreduce.map.java.opts	-Xmx512m
dfs.ha.automatic-failover.enabled	false
yarn.resourcemanager.scheduler.monitor.policies	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.leveldb-state-store.compaction-interval-secs	3600
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size	10
mapred.child.java.opts	-Xmx200m
dfs.client.https.need-auth	false
yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds	3600
dfs.namenode.write-lock-reporting-threshold-ms	5000
fs.ftp.host.port	21
fs.s3a.block.size	32M
dfs.namenode.avoid.read.stale.datanode	false
mapreduce.job.end-notification.retry.attempts	0
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms	300000
yarn.nodemanager.runtime.linux.allowed-runtimes	default
yarn.ipc.rpc.class	org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
dfs.namenode.lease-recheck-interval-ms	2000
dfs.client.block.write.locateFollowingBlock.initial.delay.ms	400
mapreduce.cluster.acls.enabled	false
mapred.output.direct.EmrFileSystem	true
yarn.nodemanager.aux-services	mapreduce_shuffle,
mapreduce.job.ubertask.maxmaps	9
dfs.hosts.exclude	/emr/instance-controller/lib/dfs.hosts.exclude
yarn.nodemanager.container-manager.thread-count	64
mapreduce.app-submission.cross-platform	false
mapreduce.job.reducer.preempt.delay.sec	0
s3native.bytes-per-checksum	512
dfs.namenode.path.based.cache.block.map.allocation.percent	0.25
yarn.app.mapreduce.am.labels	CORE
dfs.webhdfs.use.ipc.callq	true
mapreduce.reduce.markreset.buffer.percent	0.0
dfs.datanode.cache.revocation.polling.ms	500
dfs.namenode.lazypersist.file.scrub.interval.sec	300
mapreduce.jobhistory.recovery.store.fs.uri	${hadoop.tmp.dir}/mapred/history/recoverystore
hadoop.registry.zk.retry.interval.ms	1000
io.compression.codec.lzo.class	com.hadoop.compression.lzo.LzoCodec
yarn.nodemanager.keytab	/etc/krb5.keytab
nfs.dump.dir	/tmp/.hdfs-nfs
mapreduce.job.user.name	hadoop
yarn.nodemanager.delete.debug-delay-sec	0
yarn.timeline-service.ttl-enable	true
yarn.resourcemanager.fs.state-store.retry-policy-spec	2000, 500
mapreduce.reduce.skip.maxgroups	0
fs.trash.interval	0
mapreduce.job.name	streamjob4487009811121016911.jar
yarn.nodemanager.resource-monitor.interval-ms	3000
mapreduce.jobhistory.done-dir	${yarn.app.mapreduce.am.staging-dir}/history/done
hadoop.security.instrumentation.requires.admin	false
nfs.rtmax	1048576
yarn.resourcemanager.container.liveness-monitor.interval-ms	600000
dfs.namenode.backup.address	0.0.0.0:50100
dfs.namenode.max-lock-hold-to-release-lease-ms	25
dfs.datanode.readahead.bytes	4194304
mapreduce.jobhistory.cleaner.enable	true
dfs.client.block.write.retries	3
ha.failover-controller.graceful-fence.connection.retries	1
httpfs.buffer.size	4096
dfs.namenode.safemode.threshold-pct	0.999f
yarn.nodemanager.disk-health-checker.enable	true
hadoop.security.java.secure.random.algorithm	SHA1PRNG
mapreduce.job.cache.archives	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/domainrank_ccmr.tar.gz#domainrank_ccmr.tar.gz
dfs.datanode.dns.nameserver	default
mapreduce.cluster.temp.dir	${hadoop.tmp.dir}/mapred/temp
mapreduce.client.submit.file.replication	10
yarn.fail-fast	false
dfs.namenode.edits.journal-plugin.qjournal	org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
dfs.client.write.exclude.nodes.cache.expiry.interval.millis	600000
dfs.client.mmap.cache.timeout.ms	3600000
io.skip.checksum.errors	false
yarn.timeline-service.hostname	ip-192-168-27-182.ec2.internal
yarn.acl.enable	false
fs.s3a.fast.upload	false
file.blocksize	67108864
hadoop.rpc.socket.factory.class.default	org.apache.hadoop.net.StandardSocketFactory
yarn.resourcemanager.delegation-token-renewer.thread-count	50
fs.AbstractFileSystem.swebhdfs.impl	org.apache.hadoop.fs.SWebHdfs
hadoop.common.configuration.version	0.23.0
yarn.resourcemanager.client.thread-count	64
dfs.datanode.drop.cache.behind.reads	false
mapreduce.job.output.value.class	org.apache.hadoop.io.Text
mapreduce.output.fileoutputformat.outputdir	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/5cluster-1-attempt0
stream.reduce.streamprocessor	%2Fbin%2Fbash+-x+setup-wrapper.sh+python+domainrank.py+--step-num%3D2+--reducer+--iterations+1+--sortrank+1
hadoop.proxyuser.hue.hosts	*
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern	^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
yarn.resourcemanager.zk-timeout-ms	10000
yarn.resourcemanager.max-completed-applications	10000
yarn.sharedcache.cleaner.period-mins	1440
dfs.xframe.value	SAMEORIGIN
mapreduce.job.end-notification.max.retry.interval	5000
mapreduce.job.acl-view-job	
yarn.node-labels.fs-store.retry-policy-spec	2000, 500
yarn.app.mapreduce.am.job.task.listener.thread-count	60
yarn.app.mapreduce.am.resource.cpu-vcores	1
dfs.namenode.edit.log.autoroll.check.interval.ms	300000
mapreduce.map.skip.proc-count.auto-incr	true
hadoop.security.group.mapping.ldap.search.attr.member	member
hadoop.ssl.client.conf	ssl-client.xml
yarn.sharedcache.root-dir	/sharedcache
dfs.journalnode.https-address	0.0.0.0:8481
hadoop.security.groups.cache.background.reload	false
mapreduce.reduce.shuffle.fetch.retry.timeout-ms	30000
dfs.bytes-per-checksum	512
dfs.namenode.max.objects	0
dfs.datanode.max.transfer.threads	4096
dfs.block.access.key.update.interval	600
mapreduce.map.output.key.class	org.apache.hadoop.io.Text
mapreduce.map.memory.mb	768
dfs.datanode.directoryscan.throttle.limit.ms.per.sec	1000
dfs.datanode.hdfs-blocks-metadata.enabled	false
dfs.image.transfer.chunksize	65536
mapreduce.jobhistory.jhist.format	json
dfs.client.https.keystore.resource	ssl-client.xml
yarn.resourcemanager.connect.retry-interval.ms	30000
yarn.timeline-service.webapp.address	${yarn.timeline-service.hostname}:8188
yarn.scheduler.minimum-allocation-mb	32
yarn.sharedcache.cleaner.resource-sleep-ms	0
net.topology.impl	org.apache.hadoop.net.NetworkTopology
io.seqfile.compress.blocksize	1000000
fs.AbstractFileSystem.ftp.impl	org.apache.hadoop.fs.ftp.FtpFs
dfs.namenode.checkpoint.edits.dir	${dfs.namenode.checkpoint.dir}
mapreduce.job.running.reduce.limit	0
dfs.namenode.heartbeat.recheck-interval	300000
dfs.namenode.safemode.extension	5000
mapreduce.job.reduce.shuffle.consumer.plugin.class	org.apache.hadoop.mapreduce.task.reduce.Shuffle
yarn.nodemanager.vmem-check-enabled	true
dfs.http.client.failover.sleep.base.millis	500
dfs.namenode.delegation.key.update-interval	86400000
hadoop.rpc.protection	authentication
fs.permissions.umask-mode	022
hadoop.http.staticuser.user	dr.who
fs.s3a.connection.maximum	15
fs.s3a.paging.maximum	5000
yarn.resourcemanager.delegation.token.renew-interval	86400000
ipc.maximum.response.length	134217728
hadoop.shell.missing.defaultFs.warning	false
hadoop.http.authentication.kerberos.keytab	${user.home}/hadoop.keytab
yarn.nodemanager.container-localizer.java.opts	-Xmx256m
dfs.client.block.write.replace-datanode-on-failure.enable	true
dfs.client.use.legacy.blockreader.local	false
dfs.namenode.checkpoint.dir	file://${hadoop.tmp.dir}/dfs/namesecondary
dfs.webhdfs.rest-csrf.browser-useragents-regex	^Mozilla.*,^Opera.*
dfs.namenode.top.windows.minutes	1,5,25
mapreduce.job.maxtaskfailures.per.tracker	3
net.topology.node.switch.mapping.impl	org.apache.hadoop.net.ScriptBasedMapping
mapreduce.shuffle.max.connections	0
yarn.client.application-client-protocol.poll-interval-ms	200
yarn.nodemanager.localizer.address	${yarn.nodemanager.hostname}:8040
dfs.namenode.list.cache.pools.num.responses	100
nfs.server.port	2049
fs.s3a.readahead.range	64K
ha.zookeeper.parent-znode	/hadoop-ha
yarn.sharedcache.admin.thread-count	1
yarn.nodemanager.resource.cpu-vcores	4
mapreduce.jobhistory.http.policy	HTTP_ONLY
fs.s3a.attempts.maximum	20
yarn.log-aggregation.retain-check-interval-seconds	-1
fs.s3n.multipart.copy.block.size	5368709120
mapreduce.job.jar	/tmp/hadoop-yarn/staging/hadoop/.staging/job_1537422601105_0009/job.jar
mapred.output.committer.class	org.apache.hadoop.mapred.DirectFileOutputCommitter
yarn.resourcemanager.node-ip-cache.expiry-interval-secs	-1
yarn.resourcemanager.zk-acl	world:anyone:rwcda
yarn.timeline-service.client.fd-clean-interval-secs	60
hadoop.ssl.keystores.factory.class	org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
mapreduce.job.split.metainfo.maxsize	10000000
fs.s3.maxRetries	4
hadoop.security.random.device.file.path	/dev/urandom
yarn.client.nodemanager-connect.max-wait-ms	180000
yarn.app.mapreduce.client-am.ipc.max-retries	3
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage	false
dfs.replication.max	512
dfs.datanode.https.address	0.0.0.0:50475
ipc.client.kill.max	10
mapreduce.job.committer.setup.cleanup.needed	true
dfs.client.domain.socket.data.traffic	false
yarn.nodemanager.localizer.cache.target-size-mb	10240
yarn.resourcemanager.admin.client.thread-count	1
hadoop.security.group.mapping.ldap.connection.timeout.ms	60000
yarn.timeline-service.store-class	org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
hadoop.tmp.dir	/mnt/var/lib/hadoop/tmp
hadoop.security.kms.client.failover.sleep.base.millis	100
yarn.node-labels.configuration-type	centralized
yarn.timeline-service.ttl-ms	604800000
mapreduce.task.exit.timeout.check-interval-ms	20000
mapreduce.map.speculative	true
yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms	1000
yarn.timeline-service.recovery.enabled	false
yarn.nodemanager.recovery.dir	${hadoop.tmp.dir}/yarn-nm-recovery
mapreduce.job.counters.max	120
dfs.namenode.max.full.block.report.leases	6
yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms	20
dfs.namenode.max.extra.edits.segments.retained	10000
dfs.webhdfs.user.provider.user.pattern	^[A-Za-z_][A-Za-z0-9._-]*[$]?$
dfs.client.mmap.enabled	true
mapreduce.map.log.level	INFO
dfs.client.file-block-storage-locations.timeout.millis	1000
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms	1000
hadoop.fuse.timer.period	5
ha.health-monitor.check-interval.ms	1000
yarn.nodemanager.docker-container-executor.exec-name	/usr/bin/docker
yarn.resourcemanager.fs.state-store.retry-interval-ms	1000
mapreduce.output.fileoutputformat.compress	true
io.native.lib.available	true
yarn.sharedcache.store.in-memory.staleness-period-mins	10080
mapreduce.input.fileinputformat.inputdir	hdfs:/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/step-output/0001
hadoop.security.group.mapping.providers.combined	true
fs.AbstractFileSystem.har.impl	org.apache.hadoop.fs.HarFs
mapreduce.job.running.map.limit	0
mapreduce.reduce.input.buffer.percent	0.0
yarn.nodemanager.webapp.address	${yarn.nodemanager.hostname}:8042
mapreduce.job.cache.files	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/domainrank.py#domainrank.py,hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/mrjob.zip#mrjob.zip,hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop/tmp/mrjob/domainrank.hadoop.20180920.092428.447818/files/setup-wrapper.sh#setup-wrapper.sh
fs.s3a.multipart.size	100M
dfs.client.slow.io.warning.threshold.ms	30000
yarn.app.mapreduce.am.job.committer.commit-window	10000
yarn.app.mapreduce.am.jhs.backup.enabled	true
mapreduce.job.submithostname	ip-192-168-27-182.ec2.internal
dfs.namenode.edits.asynclogging	true
mapreduce.ifile.readahead	true
s3native.replication	3
stream.addenvironment	HADOOP_ROOT_LOGGER=
yarn.timeline-service.entity-group-fs-store.summary-store	org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
s3.stream-buffer-size	4096
dfs.datanode.fsdatasetcache.max.threads.per.volume	4
fs.s3a.socket.recv.buffer	8192
mapreduce.output.fileoutputformat.compress.codec	org.apache.hadoop.io.compress.BZip2Codec
fs.adl.impl	org.apache.hadoop.fs.adl.AdlFileSystem
yarn.sharedcache.store.in-memory.initial-delay-mins	10
mapreduce.jobhistory.webapp.address	ip-192-168-27-182.ec2.internal:19888
mapreduce.task.userlog.limit.kb	0
fs.s3a.connection.ssl.enabled	true
hadoop.proxyuser.hadoop.hosts	*
yarn.sharedcache.webapp.address	0.0.0.0:8788
dfs.http.client.retry.policy.spec	10000,6,60000,10
hadoop.fuse.connection.timeout	300
mapreduce.input.fileinputformat.numinputfiles	10
ipc.server.max.connections	0
yarn.resourcemanager.rm.container-allocation.expiry-interval-ms	600000
yarn.app.mapreduce.am.resource.mb	1024
hadoop.security.groups.cache.secs	300
mapred.reducer.class	org.apache.hadoop.streaming.PipeReducer
s3.client-write-packet-size	65536
dfs.replication	1
mapreduce.shuffle.transfer.buffer.size	131072
hadoop.security.group.mapping.ldap.directory.search.timeout	10000
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold	10737418240
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts	3
yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs	3600
yarn.scheduler.maximum-allocation-vcores	128
yarn.nodemanager.sleep-delay-before-sigkill.ms	250
mapreduce.job.acl-modify-job	
fs.automatic.close	true
hadoop.proxyuser.httpfs.hosts	*
hadoop.security.groups.cache.background.reload.threads	3
mapreduce.input.fileinputformat.list-status.num-threads	1
hadoop.security.group.mapping.ldap.posix.attr.gid.name	gidNumber
dfs.namenode.acls.enabled	false
dfs.client.short.circuit.replica.stale.threshold.ms	1800000
fs.s3.block.size	67108864
dfs.namenode.resource.du.reserved	104857600
mapreduce.shuffle.listen.queue.size	128
mapreduce.jobhistory.intermediate-done-dir	${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
dfs.namenode.edits.noeditlogchannelflush	false
yarn.nodemanager.recovery.compaction-interval-secs	3600
mapreduce.reduce.shuffle.input.buffer.percent	0.70
mapreduce.map.maxattempts	4
yarn.http.policy	HTTP_ONLY
dfs.namenode.audit.loggers	default
hadoop.security.groups.cache.warn.after.ms	5000
io.serializations	org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
hadoop.http.cross-origin.allowed-methods	GET,POST,HEAD
yarn.node-labels.fs-store.impl.class	org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore
dfs.http.policy	HTTP_ONLY
stream.map.input.writer.class	org.apache.hadoop.streaming.io.TextInputWriter
dfs.client.file-block-storage-locations.num-threads	10
mapreduce.cluster.local.dir	/mnt/mapred
dfs.namenode.secondary.https-address	0.0.0.0:50091
hadoop.kerberos.kinit.command	kinit
dfs.namenode.metrics.logger.period.seconds	600
dfs.block.access.token.lifetime	600
dfs.namenode.delegation.token.max-lifetime	604800000
dfs.datanode.drop.cache.behind.writes	false
mapreduce.local.clientfactory.class.name	org.apache.hadoop.mapred.LocalClientFactory
dfs.namenode.num.extra.edits.retained	1000000
dfs.namenode.replication.considerLoad.factor	2.0
fs.viewfs.rename.strategy	SAME_MOUNTPOINT
ipc.client.connect.max.retries.on.timeouts	5
hadoop.proxyuser.hive.hosts	*
yarn.resourcemanager.node-labels.provider.fetch-interval-ms	1800000
yarn.nodemanager.container-metrics.enable	false
fs.s3n.block.size	67108864
mapreduce.job.map.output.collector.class	org.apache.hadoop.mapred.MapTask$MapOutputBuffer
fs.s3a.fast.upload.buffer	disk
ha.health-monitor.connect-retry-interval.ms	1000
dfs.namenode.edekcacheloader.initial.delay.ms	3000
mapreduce.tasktracker.map.tasks.maximum	1
dfs.client.datanode-restart.timeout	30
io.mapfile.bloom.size	1048576
hadoop.security.kms.client.authentication.retry-count	1
dfs.client-write-packet-size	65536
fs.swift.impl	org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
yarn.app.mapreduce.shuffle.log.backups	0
ftp.blocksize	67108864
yarn.log.server.url	http://ip-192-168-27-182.ec2.internal:19888/jobhistory/logs
dfs.namenode.kerberos.principal.pattern	*
yarn.resourcemanager.scheduler.monitor.enable	false
dfs.webhdfs.socket.connect-timeout	60s
nfs.allow.insecure.ports	true
mapreduce.job.cache.archives.visibilities	true
yarn.sharedcache.nm.uploader.thread-count	20
fs.AbstractFileSystem.s3.impl	org.apache.hadoop.fs.s3.EMRFSDelegate
hadoop.proxyuser.hadoop.groups	*
mapreduce.job.cache.archives.filesizes	1001386
yarn.app.mapreduce.client.job.retry-interval	2000
hadoop.security.authorization	false
yarn.timeline-service.version	1.0f
yarn.am.liveness-monitor.expiry-interval-ms	600000
fs.har.impl.disable.cache	true
dfs.namenode.upgrade.domain.factor	${dfs.replication}
yarn.timeline-service.leveldb-timeline-store.path	${hadoop.tmp.dir}/yarn/timeline
mapreduce.job.reduce.slowstart.completedmaps	0.05
fs.s3.impl	com.amazon.ws.emr.hadoop.fs.EmrFileSystem
mapreduce.jobhistory.minicluster.fixed.ports	false
mapreduce.application.classpath	$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*, $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*, /usr/lib/hadoop-lzo/lib/*, /usr/share/aws/emr/emrfs/conf, /usr/share/aws/emr/emrfs/lib/*, /usr/share/aws/emr/emrfs/auxlib/*, /usr/share/aws/emr/lib/*, /usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar, /usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar, /usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar, /usr/share/aws/emr/cloudwatch-sink/lib/*, /usr/share/aws/aws-java-sdk/*
yarn.resourcemanager.delegation.token.max-lifetime	604800000
yarn.resourcemanager.ha.automatic-failover.enabled	true
mapreduce.reduce.java.opts	-Xmx768m
mapreduce.job.userlog.retain.hours	48
dfs.namenode.accesstime.precision	3600000
mapreduce.map.output.value.class	org.apache.hadoop.io.Text
io.mapfile.bloom.error.rate	0.005
yarn.resourcemanager.store.class	org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
yarn.timeline-service.leveldb-state-store.path	${hadoop.tmp.dir}/yarn/timeline
hadoop.proxyuser.hive.groups	*
dfs.namenode.support.allow.format	true
yarn.resourcemanager.nodes.exclude-path	/emr/instance-controller/lib/yarn.nodes.exclude.xml
yarn.nodemanager.container-executor.class	org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
mapred.map.runner.class	org.apache.hadoop.streaming.PipeMapRunner
mapred.output.direct.NativeS3FileSystem	true
dfs.namenode.top.enabled	true
yarn.app.mapreduce.shuffle.log.separate	true
hadoop.security.kms.client.encrypted.key.cache.low-watermark	0.3f
hadoop.user.group.static.mapping.overrides	dr.who=;
yarn.nodemanager.amrmproxy.address	0.0.0.0:8048
dfs.client.cached.conn.retry	3
dfs.namenode.path.based.cache.refresh.interval.ms	30000
dfs.namenode.fs-limits.max-directory-items	1048576
yarn.resourcemanager.zk-retry-interval-ms	1000
yarn.nodemanager.runtime.linux.docker.capabilities	CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE
dfs.ha.log-roll.period	120
yarn.minicluster.fixed.ports	false
ipc.client.fallback-to-simple-auth-allowed	false
yarn.nodemanager.remote-app-log-dir	/var/log/hadoop-yarn/apps
yarn.timeline-service.entity-group-fs-store.scan-interval-seconds	60
dfs.xframe.enabled	true
yarn.nodemanager.resource.percentage-physical-cpu-limit	100
dfs.namenode.fs-limits.max-xattr-size	16384
dfs.datanode.http.address	0.0.0.0:50075
dfs.namenode.blocks.per.postponedblocks.rescan	10000
hadoop.jetty.logs.serve.aliases	true
dfs.webhdfs.ugi.expire.after.access	600000
mapreduce.jobhistory.admin.acl	*
mapreduce.job.reducer.unconditional-preempt.delay.sec	300
yarn.app.mapreduce.am.hard-kill-timeout-ms	10000
yarn.resourcemanager.node-removal-untracked.timeout-ms	60000
yarn.resourcemanager.webapp.address	${yarn.resourcemanager.hostname}:8088
mapreduce.jobhistory.recovery.enable	false
yarn.sharedcache.store.in-memory.check-period-mins	720
fs.df.interval	60000
yarn.timeline-service.enabled	true
fs.s3n.impl	com.amazon.ws.emr.hadoop.fs.EmrFileSystem
hadoop.http.cross-origin.allowed-headers	X-Requested-With,Content-Type,Accept,Origin
mapreduce.task.profile	false
yarn.nodemanager.hostname	0.0.0.0
mapreduce.task.exit.timeout	60000
mapreduce.job.token.tracking.ids.enabled	false
yarn.scheduler.increment-allocation-mb	32
hadoop.security.kms.client.failover.sleep.max.millis	2000
dfs.client.mmap.retry.timeout.ms	300000
mapreduce.jobhistory.move.thread-count	3
dfs.permissions.enabled	true
fs.AbstractFileSystem.hdfs.impl	org.apache.hadoop.fs.Hdfs
hadoop.http.filter.initializers	org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer
yarn.timeline-service.http-authentication.simple.anonymous.allowed	true
yarn.sharedcache.client-server.thread-count	50
yarn.resourcemanager.resource-tracker.address	ip-192-168-27-182.ec2.internal:8025
mapreduce.job.working.dir	hdfs://ip-192-168-27-182.ec2.internal:8020/user/hadoop
mapreduce.jobhistory.jobname.limit	50
dfs.namenode.decommission.blocks.per.interval	500000
rpc.metrics.quantile.enable	false
dfs.namenode.read-lock-reporting-threshold-ms	5000
mapreduce.task.timeout	600000
yarn.nodemanager.resource.memory-mb	2048
yarn.nodemanager.disk-health-checker.min-healthy-disks	0.25
dfs.datanode.failed.volumes.tolerated	0
mapreduce.fileoutputcommitter.algorithm.version	1
mapreduce.framework.name	yarn
yarn.resourcemanager.system-metrics-publisher.enabled	true
yarn.sharedcache.nested-level	3
hadoop.caller.context.signature.max.size	40
fs.s3a.connection.timeout	200000
hadoop.security.dns.log-slow-lookups.enabled	false
mapreduce.jobhistory.webapp.https.address	0.0.0.0:19890
file.client-write-packet-size	65536
ipc.client.ping	true
mapreduce.job.cache.files.filesizes	7746,297015,678
hadoop.proxyuser.oozie.hosts	*
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms	30000
dfs.client.failover.max.attempts	15
yarn.nodemanager.webapp.cross-origin.enabled	false
dfs.client.read.shortcircuit.streams.cache.expiry.ms	300000
dfs.balancer.max-no-move-interval	60000
yarn.minicluster.control-resource-monitoring	false
mapreduce.client.genericoptionsparser.used	true
yarn.nodemanager.health-checker.script.timeout-ms	1200000
yarn.resourcemanager.fs.state-store.num-retries	0
hadoop.ssl.require.client.cert	false
hadoop.security.uid.cache.secs	14400
mapreduce.jobhistory.keytab	/etc/security/keytab/jhs.service.keytab
yarn.resourcemanager.ha.automatic-failover.zk-base-path	/yarn-leader-election
yarn.intermediate-data-encryption.enable	false
mapreduce.job.speculative.speculative-cap-running-tasks	0.1
dfs.datanode.block.id.layout.upgrade.threads	12
dfs.client.context	default
dfs.namenode.delegation.token.renew-interval	86400000
yarn.timeline-service.entity-group-fs-store.app-cache-size	10
fs.AbstractFileSystem.s3a.impl	org.apache.hadoop.fs.s3a.S3A
dfs.datanode.fsdataset.volume.choosing.policy	org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy
ipc.client.tcpnodelay	true
yarn.dispatcher.exit-on-error	true
hadoop.proxyuser.httpfs.groups	hudson,testuser,root,hadoop,jenkins,oozie,hive,httpfs,hue,users
yarn.resourcemanager.metrics.runtime.buckets	60,300,1440
mapreduce.job.cache.files.visibilities	true,true,true
dfs.blockreport.intervalMsec	21600000
yarn.client.application-client-protocol.poll-timeout-ms	-1
io.map.index.skip	0
mapreduce.job.hdfs-servers	${fs.defaultFS}
mapreduce.map.output.compress	true
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads	2
fs.s3n.multipart.uploads.block.size	67108864
dfs.namenode.edekcacheloader.interval.ms	1000
mapreduce.task.merge.progress.records	10000
yarn.nodemanager.aux-services.mapreduce_shuffle.class	org.apache.hadoop.mapred.ShuffleHandler
tfile.fs.output.buffer.size	262144
fs.du.interval	600000
dfs.client.failover.connection.retries	0
dfs.namenode.top.window.num.buckets	10
mapreduce.job.dir	/tmp/hadoop-yarn/staging/hadoop/.staging/job_1537422601105_0009
yarn.sharedcache.uploader.server.address	0.0.0.0:8046
dfs.http.client.failover.max.attempts	15
rpc.engine.org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB	org.apache.hadoop.ipc.ProtobufRpcEngine
fs.s3a.socket.send.buffer	8192
mapreduce.jvm.system-properties-to-log	os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name
hadoop.registry.zk.quorum	localhost:2181
hadoop.http.cross-origin.allowed-origins	*
dfs.namenode.enable.retrycache	true
mapreduce.job.cache.archives.timestamps	1537435499911
dfs.datanode.du.reserved	536870912
hadoop.registry.system.acls	sasl:yarn@, sasl:mapred@, sasl:hdfs@
mapreduce.task.profile.reduce.params	${mapreduce.task.profile.params}
mapreduce.admin.user.env	LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native:/usr/lib/hadoop-lzo/lib/native
mapreduce.reduce.memory.mb	1024
hadoop.http.authentication.kerberos.principal	HTTP/_HOST@LOCALHOST
hadoop.caller.context.enabled	false
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb	0
hadoop.security.sensitive-config-keys	secret$ password$ ssl.keystore.pass$ fs.s3.*[Ss]ecret.?[Kk]ey fs.azure.account.key.* credential$ oauth.*token$ hadoop.security.sensitive-config-keys
mapreduce.client.completion.pollinterval	5000
dfs.namenode.name.dir.restore	false
dfs.namenode.full.block.report.lease.length.ms	300000
dfs.namenode.secondary.http-address	0.0.0.0:50090
hadoop.security.group.mapping.ldap.read.timeout.ms	60000
s3.bytes-per-checksum	512
yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory	10
yarn.resourcemanager.webapp.https.address	${yarn.resourcemanager.hostname}:8090